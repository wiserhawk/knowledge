=======================================
	S3 (SIMPLE STORAGE SERVICE)
=======================================

	===========================
	What is S3?
	===========================
	- S3 provides developers an IT teams with secure, durable, highly-scalable object storage.
	- Amazon S3 is easy to use, with simple web serevice interface to store and retrieve any amount of data from anywhere on the web.
	- S3 is safe place to store your files.
	- It is object based storage. i.e allows you to upload files.
	- Data is shared across multiple devices and facilities.
	- File can be from 0 Bytes to 5 TB.
	- The largest object that can be uploaded in a single PUT is 5 gigabytes. For objects larger than 100 MB, 
	  customers should consider using the Multipart Upload capability. The multipart upload API is designed to improve 
	  the upload experience for larger objects. You can upload objects in parts. These object parts can be uploaded independently, 
	  in any order, and in parallel. You can use a multipart upload for objects from 5 MB to 5 TB in size. 
	- There is unlimited storage.
	- Files are stored in Buckets. Bucket is just a directory to store files.
	- S3 is a universal namespace. That means bucket names must be unique globally. for example,
		Global: https://uniquebucket.s3.amazonaws.com/
		Regional: https://uniquebucket.eu-west-1.amazonaws.com/
	- When you upload a file to S3 bucket, you will receive a HTTP 200 status code if the file upload was successful.
	
	============================
	S3 Objects
	============================
	- S3 is object based. Think of Objects just as files.
	- Objects consist of the following:
		- Key (This is simply the name of the object)
		- Value (This is simply the data and is made up of a sequence of bytes)
		- VersionID (Important of versioning, S3 allows mutiple versions of a file)
		- Metadata (Data about data you are storing)
		- Subresources:
			- Access Control Lists: Amazon S3 access control lists (ACLs) enable you to manage access to buckets and objects. 
			  Each bucket and object has an ACL attached to it as a subresource. It defines which AWS accounts or groups are 
			  granted access and the type of access. When a request is received against a resource, Amazon S3 checks the 
			  corresponding ACL to verify that the requester has the necessary access permissions.
			- Torrent: The torrent subresource to return torrent files from a bucket. BitTorrent can save you bandwidth when 
			  you're distributing large files
	
	============================
	S3 Obejcts Consistency
	============================
	- Read After Write consistency for PUTS of new objects. It means if you upload a new file to S3 you can read its data immediately.
	- Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate). 
	  That means if you update file (overwrite with new version) or delete file and try to read it immediately 
	  in that case you may read older version or may not. Basically changes to objects can take a little bit of time to propagate.	
	  
	============================
	S3 Guarantees
	============================
	- Built for 99.99% availability for the S3 platform.
	- Amazon Guarantee 99.9% availability.
	- Amazon guarantees 99.999999999% durability for S3 data (Remember 11x9s).
	
	============================
	S3 Features
	============================
	- Tiered Storage Available: Multiple tier types are available to stored data based on it usages and costs.
	- Lifecycle Management: Data can be move from one bucket to another bucket or one tier to another tier as a data lifecycle.
	- Versioning: Single data file can have multiple versions of it by enabling versioning on bucket.
	- Encryption: You can encrypt your data files at rest using multiple encryption types.
	- MFA Delete: You can enable Multy Factor Authentication to delete objects.
	- Secure data using Access Control Lists and Bucket Policies.
	
	======================================================================
	S3 Storage Classes (Tiers) https://aws.amazon.com/s3/storage-classes/
	======================================================================
	- S3 STANDARD: 99.99% availability, 99.999999999% durability, stored redundantly across multiple devices in multiple facilities, 
	  and is designed to sustain the loss of 2 facilities concurrently.
	- S3-IA (Infrequently Accessed): For the data that is accessed less frequently, but requires rapid access when needed. 
	  Lower fee than S3 Standard, but you are charged a retrieval fee.
	- S3 ONE ZONE-IA: For where you want lower-cost option for infrequently accessed data, 
	  but don't require the multiple Availability Zone data resiliency.
	- S3 INTELLIGENT-TIERING: Designed to optimize costs by automatically moving data to the most cost-effective access tier, 
	  without performance impact or operational overhead. It use machine learning to identify how often you use particular data 
	  and move them to its suitable S3 tier.
	- S3 GLACIER: S3 Glacier is a secure, durable, and low-cost storage class for data archiving. 
	  You can reliably store any amount of data at costs that are competitive with or cheaper then on-permises solutions. 
	  Retrieval times configurable from minutes to hours.
	- S3 GLACIER DEEP ARCHIVE: S3 Glacier Deep Archive is  mazon S3's lowest-cost storage class where a retrieval time of 12 hours is acceptable.
	
	===========================================
	Performance Across the S3 Storage Classes
	===========================================
	- https://aws.amazon.com/s3/storage-classes/
	
	============================
	S3 Charges
	============================
	- You are charged for S3 in the following ways:
		- STORAGE: Based on size of data stored.
		- REQUESTES: Based on how many I/O requests gone to S3 bucket.
		- STORAGE MANAGEMENT CHARGES: Data management charges for managing data on S3 for long times.
		- DATA TRANSFER CHARGES: Based on amount of data transfered in or out over S3.
		- TRANSFER ACCELERATION: Amazon S3 Transfer Acceleration enables fast, easy and secure transfers of files over long distances 
		  between your end users and a S3 bucket. Transfer Acceleration takes advantage of Amazon CloudFront's (CDN) globally distributed 
		  edge locations, data is routed to Amazon S3 over an optimized network path.
		- CROSS REGION REPLICATION CHARGES: You can replicate data over different region buckets for high availability and disaster management.
		  you can turn on cross region replicate for auto replication. 
		- PROVISIONED CAPACITY: AWS S3 Glacier allow your to pay a fixed up-front fee to expedite retrievals from S3 Glacier vaults for a given month.
		
	========================================================
	What is S3 Glacier Provisioned Capacity?
	========================================================
	- Amazon S3 Glacier provisioned capacity units allow you to pay a fixed up-front fee to expedite retrievals from Amazon S3 Glacier vaults 
	  for a given month. You can purchase multiple provisioned capacity units per month to increase the amount of data you can retrieve.
	- Important: Most use cases don't require the purchase of provisioned capacity units. Purchase provisioned capacity units only if:
	
	- When should you use it?
		- You have a lot of data stored in Amazon S3 Glacier.
		- You plan to frequently retrieve large amounts of data from Amazon S3 Glacier in a given month.
		- Your use case demands that the data you retrieve is accessible within minutes.
	
	- Glacier archive Retrieval Options
		- Expedited: Expedited retrievals allow you to quickly access your data when occasional urgent requests for a subset of archives are required.
			For all but the largest archives (250 MB+), data accessed using Expedited retrievals are typically made available within 1–5 minutes. 
			Provisioned Capacity ensures that retrieval capacity for Expedited retrievals is available when you need it. For more information, 
			see Provisioned Capacity.
		- Standard: Standard retrievals allow you to access any of your archives within several hours. Standard retrievals typically complete 
			within 3–5 hours. This is the default option for retrieval requests that do not specify the retrieval option.
		- Bulk: Bulk retrievals are S3 Glacier’s lowest-cost retrieval option, which you can use to retrieve large amounts, even petabytes, 
			of data inexpensively in a day. Bulk retrievals typically complete within 5–12 hours.
	============================
	Exam Tips
	============================
	- READ THE S3 FAQs BEFORE TAKING THE EXAM. IT COMES UP A LOT!!!!!!!!	
	- Remember that S3 is Obejct-based. i.e. allow you to to upload files.
	- Files can be from 0 Bytes to 5 TB.
	- There is unlimited storage.
	- Files are stored in buckets.
	- S3 is a universal namespace. That is, name must be unique globally.
	- A unique DNS name get created for bucket.
	- It is only for files storage, Not suitable to install an operating systems / databases on.
	- Successful upload will generate a HTTP 200 status code.
	- You can turn on MFA on delete object. To protect from accidental delete.
	- By default, you can create up to 100 buckets in each of your AWS accounts. If you need additional buckets, 
	  you can increase your account bucket limit to a maximum of 1,000 buckets by submitting a service limit increase.
	- Objects consist of the following:
		- Key (This is simply the name of the object)
		- Value (This is simply the data and is made up of a sequence of bytes)
		- VersionID (Important of versioning, S3 allows mutiple versions of a file)
		- Metadata (Data about data you are storing)
		- Subresources:
			- Access Control Lists
			- Torrent
	- Read After Write Consistency for PUTS of new objects.
	- Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate). 
	- Storage Classes
		- S3 Standard
		- S3-IA (Infrequently Accessed)
		- S3 One Zone-IA
		- S3 Intelligent-Tiering	
		- S3 Glacier
		- S3 Glacier Deep Archive
		- Comparison among all classes - https://aws.amazon.com/s3/storage-classes/
	
	=============================================
	S3 Security & Encryption
	=============================================
	- By default, all newly created buckets are PRIVATE. You can setup access control to your buckets using:
		- Bucket Policies: it works on bucket level.
		- Access Control Lists: it works on individual object level.
	- S3 buckets can be configured to create access logs which log all requests made to the S3 bucket.
	  This can be sent to another bucket and even anoher bucket in another account.
	- Encryption In Transit (over https) is achieved by:
		- SSL/TLS
	- Encryption At Rest(Server Side) is achieved by:
		- S3 Managed Keys - SSE-S3 (Keys from AWS S3)
		- AWS Key Management Service, Managed Keys - SSE-KMS (Keys from AWS S3 & Keys from Customer)
		- Server Side Encryption With Customer Provided Keys SSE-C (Keys from Customer)
	- Client Side Encryption 
		- client can encrypt object at their level and then upload it to S3 buckets.
		
	===============================================
	S3 Versioning 
	===============================================
	- Stores all versions of an object (including all writes and even if you delete an object)
	- Greate backup tool.
	- Once enabled, Versioning cannot be disabled, only suspended.
	- Integrates with Lifecycle rules.
	- Versioning's MFA Delete capability, which uses multi-factor authentication, can be used to provide an additional layer of security.
	- Newly ploaded version of a file don't inharit permission from older version. you have to provide permission explicitly.
	
	===============================================
	S3 Lifecycle Management
	===============================================
	- Automates moving your objects between the different storage tiers.
	- Can be used in conjunction with versioning.
	- Can apply to current versions and previous versions. 
	
	================================================
	S3 Lock Policies & Glacier Vault Lock [SAA-C02]
	================================================
	- What is S3 Object Lock?
		- You can use S3 Object Lock to store objects using a write once, read many (WORM) model. It can help you prevent objects
		  from being deleted or modified for a fixed amount of time or indefinitely.
		- You can use S3 Object Lock to meet regulatory requirements that require WORM storage, or add a extra layer of protection
		  against object changes and deletion.
		- Object locks can be applied on individual objects or applied across the bucket as a whole.
		  
	- S3 Object Lock Modes:
		- Governance Mode: 
			- In governance mode, users can't overwrite or delete an object version or alter its lock settings unless they have special
			  permissions. With governance mode, you protect objects against being deleted by most users, but you can still grant some 
			  users permission to alter the retention setting or delete the object if necessary.
		- Compliance Mode:
			- In compliance mode, a protected object version can't be overwritten or deleted by any user, including the root user in 
			  your AWS account. When an object is locked in compliance mode, its retention mode can't be changed and its retention 
			  period can't be shortened. Compliance mode ensures an object version can't be overwritten or deleted for the duration
			  of the retention period.
	- What is Retention Periods?
		- A retention period protects an object version for a fixed amount of time. When you place a retention period on an object version,
		  Amazon S3 stores a timestamp in the object version's metadata to indicate when the retention period expires. After the retention
		  expires, the object version can be overwritten or deleted unless you also placed a legal hold on the object version.
		  
	- What is Legal Holds?
		- S3 Object Lock also enables you to place a legal hold on an object version. Like a retention period, a legal hold prevents an object
		  version from being overwritten or deleted. However, a legal hold doesn't have an associated retention period and remains in effect
		  untill removed. Legal holds can be freely placed and removed by any user who has the s3:PutObjectLegalHold permission.
		  
	- Glacier Vault Lock
		- S3 Glacier Vault Lock allow you to easily deploy and enforce compliance controls for individual S3 Glacier vaults with a Vault Lock policy.
		  You can specify controls, such as WORM, in a Vault Lock policy and lock the policy from future edits. Once locked, the policy can no longer 
		  be changed. 
	
	===================================================
	AWS Organizations Service & Consolidated Billing
	===================================================
	- What is AWS Organizations?
		- AWS Organizations is an account management service that enables you to consolidate multiple AWS accounts 
		  into an organization that you create and centrally manage.
		- Billing of different AWS accounts can be consolidate together as an Organization level. Basic idea behind this
		  is that in AWS "more you use, less you pay". So if you group entire aws accounts under one organization. 
		  You can save more by consolidating entire usages of accounts.
	- Advantages of Consolidated Billing
		- One bill per AWS account.
		- Very easy to track charges and allocate costs.
		- Volume pricing discounts.
	- Some Best Practices with AWS Organizations
		- Always enable multi-factor authentication on root account.
		- Always use a strong and complex password for root account.
		- Paying account should be used for billing purposes only. Don't deploy resources into the paying account.
		- Enable/Disable AWS services using Service Control Policies (SCP) either on OU (Operational Units) or on individual accounts.
		
	=============================================
	Sharing S3 Buckets Across Accounts
	=============================================
	- 3 different ways to share S3 buckets across accounts
		- Using Bucket Policies & IAM (Applies across the entire bucket). Programmatic Access Only.
		- Using Bucket ACL & IAM (Individual Objects). Programmatic Access Only.
		- Cross-account IAM Roles. Programmatic AND Console access.
	=============================================
	Cross Region Replication (CRR) of S3 Buckets
	=============================================
	- You can replicate S3 buckets across regions. To create rule for Cross Region Replication (CRR), versioning MUST be enabled on bucket.
	- While creating replication rule:
		- You can select to apply rule on entire bucket or objects using Prefix or Tags.
		- You can select destination bucket either by "Bucket in same Account" or "Bucket in another Account".
		- You need to select/create an IAM role. Provide access to S3 application on distination bucket.
	- Replication DO NOT work for already existing objects on source bucket. 
	  All newly uploaded objects on source bucket will get replicated on destination bucket.
	- Once a file get replicated among buckets. DELETE operation DO NOT get replicate across buckets.
	  This is done by AWS deliberately to protect objects from accidental deletes. If you want to delete objects,
	  you have to delete them manually.
	- Delete individual versions or delete markers will not be replicated.
	
	=============================================
	S3 Transfer Acceleration
	=============================================
	- What is S3 Transfer Acceleration?
		- S3 Transfer Acceleration utilises the CloudFront Edge Location Network to accelerate your uploads to S3.
		  Instead of uploading files directly to your S3 bucket, you can user distinct URL to upload directly to an edge location
		  which will then transfer that file to S3. You will get a distinct URL to upload to. e.g. https://thebucket.s3.accelerate.amazonaws.com
	
	=============================================
	CloudFront Overview
	=============================================
	- What is CloudFront?
		- CloudFront is a Content Delivery Network (CDN) for AWS. CDN is a system of distributed servers (network) that deliver webpages
		  and other web content to a user based on the geographic locations of the user, the origin of the webpage and a content delivery server.
		  CloudFront can be used to deliver you entire website, including dynamic, static, streaming and interactive content using global network
		  of Edge Locations. Requests for your content are automatically routed to the nearest Edge Location, so content is delivered with best
		  possible performance.
	- CloudFront Key Terminology
		- Edge Location: This is the server location where content will be cached. This is separate to an AWS Region/AZ.
		- Origin: This the origin of all files that the CDN will distribute. This can be a S3 bucket, an EC2 instance, 
		  an Elastic Load Balancer or Route53.
		- Distribution: This is the name given to CDN which consists of a collection of Edge Locations.
	- Types of Distribution using CloudFront
		- Web Distribution - Typically used for websites.
		- RTMP - Used for Media Streaming using Adobe Flash Media Server's RTMP protocol.
	- Remember
		- Edge Locations are NOT just READ only. You can write to them too. i.e. put an object on to them.
		- Objects are cached for the life of the TTL (Time to Live).
		- You can clean/invalidate cached objects, but you will be charged for this.
		- CloudFront is global service, not specific to any region.
		- You can restrict viewer access by enabling "Use Signed URLs or Signed Cookies".
		- You can invalidate data on CloudFront based on pattern (any object, or directory). It will not let objects to be distribute to edge locations.
	
	===============================================
	Snowball
	===============================================
	- What is Snowball?
		- Snowball is a petabyte-scale data transfer solution that use secure appliances to transfer large amount of data into and out of AWS.
		  Using Snowball addresses common challenges with large-scale data transfers including high network costs, long transfer times and securty
		  concerns. Transferring data with Snowball is simple, fast, secure and can be as little as one-fifth the cost of high-speed internet.
		- Snowball comes in either a 50TB or 80TB size. Snowball uses multiple layers of security designed to protect your data including 
		  tamper-resistant enclosures, 256-bit encryption, and an industry-standard Trusted Platform Module (TPM) designed to ensure both security and 
		  full-chain-custody of your data. Once the data transfer job has been processed and verified, AWS performs a software erasure of the Snowball
		  appliances.
		- Snowball can import/Export from S3.
	- What is Snowball Edge?
		- Snowball Edge is a 100TB data transfer device with on-board storage and compute capabilities. You can use Snowball Edge to move large amount
		  of data into and out of AWS, as a temporary storage tier for large local datasets, or to support local workloads in remote or offline locations.
		- Snowball Edge connects to your existing applications and infrastructure using standard storage interfaces, streamlining the data transfer process
		  and minimizing setup and integration. Snowball Edge can cluster together to form a local storage tier and process your data oo-premises, helping 
		  ensure your applications continue to run even when they are not able to access clould.
	- What is Snowmobile?	
		- AWS Snowmobile is an Exabyte-scale data transfer service used to move extermely large amounts of data to AWS. You can transfer up to 100PB 
		  per Snowmobile, a 45-foot long ruggedized shipping container, pulled by semi-trailer truck. Snowmobile make it easy to move massive volumes
		  of data to the cloud, including video libraries, image repositories, or even a complete data center migration. Transferring data with Snowmobile
		  is secure, fast and cost effective.
	- When should I use Snowball?
		
		Available Internet			Theoretical Min. Number of days to Transfer			When to consider AWS
		Connection						100TB at 80% Network Utilization				Import/Export Snowball?
		===================			===========================================			=========================
		T3 (44.736 Mbps)				269 days											2TB or more
		100 Mbps						120 days											5TB or more
		1000 Mbps						12 days												60TB or more
	  
	========================================================
	Storage Gateway
	========================================================
	- What is Storage Gateway?
		- AWS Storage Gateway is a service that connects an on-premises software appliance with cloud based storage to provide seamless and secure
		  integration between an organization's on-permises IT environment and AWS's storage infrastructure. The service enables you to securely store
		  data to the AWS cloud for scalable and cost-effective storage.
		- AWS Storage Gateway's software appliance is available for download as a virtual machine (VM) image that you install on a host	in your datacenter.
		  Storage Gateway support either VMware ESXi or Microsoft Hyper-V. Once you have installed you gateway and associate it with your AWS account through
		  the activation process, you can use the AWS Management Console to create the storage gateway option that is right for you.
	- Storage Gateway Types (Three Types)?
		- File Gateway (NFS & SMB): Way of storing files in S3.
		- Volume Gateway (iSCSI): Way to storing copies of you hard-disc drive or virtual hard-disc drive S3.
			- Stored Volumes
			- Cached Volumes
		- Tape Gateway
	- File Gateway?
		- Files are stored as objects in your S3 buckets, accessed through a Network File System (NFS) mount point. Ownership, permissions and 
		  timestamps are durably stored in S3 in the user-metadata of the object associated with the file. Once objects are transferred to S3, they
		  can be managed as native S3 objects and bucket policies such as versioning, lifecycle management, and cross-region replication apply 
		  directly to objects stored in your bucket.
	- Volume Gateway?
		- The volume interface presents your applications with disk volumes using the iSCSI block protocol.
		  Data written to these volumes can be asynchronously backed up as point-in-time snapshots of your volumes, and stored in the cloud as
		  Amazon EBS snapshots.
		  Snapshots are incremental backups that capture only changed blocks. All Snapshots storage is also compressed to minimize your storage charges.
	- Stored Volume?
		- Stored Volumes let you store your primary data locally, while asynchronously backing up that data to AWS. Stored Volumes provide your on-permises
		  applications with low-latency access to their entire datasets, while providing durable, off-site backups. You can create storage volumes and mount 
		  them as iSCSI devices from your on-permises application servers. Data written to your stored volumes is stored on your on-premises storage hardware.
		  This data is asynchronously backed up to S3 in form of EBS snapshots. 1GB to 16TM is size for stored Volumes.
	- Cached Volumes?
		- Cached Volumes let you use Amazon S3 as your primary data storage while retaining frequently accessed data locally in your storage gateway.
		  Cached Volumes minimize the need to scale your on-premises storage infrastructure, while still providing your applications with low-latency
		  access to their frequently accessed data. You can create storage volumes up to 32TB in size and attach to them as iSCSI devices from your
		  on-premises application servers. Your gateway stores data that your write to these volumes in S3 and retains recently read data in on-permises
		  storage gateway's cache and upload buffer storage. 1GB to 32TB is size for Cached Volumes.
	- Tape Gateway?
		- Tape Gateway offers durable, cost effective solution to archive your data in the AWS cloud. The (Virtual Tape Library)VTL interface it provides 
		  lets you leverage your existing tape-based backup application infrastructure to store data on virtual tape cartridges that you create on your 
		  tape gateway. Each tape gateway is preconfigured with a media changer and tape devices, which are available to your existing client backup 
		  applications as iSCSI devices. You add tape cartridges as you need to archive your data. Supported by NetBackup, Backup Exec, Veeam etc.

	================================================
	Athena vs Macie
	================================================
	- What is Athena?
		- Interactive query service which enables you to analyse and query data located in S3 using standard SQL
			- Serverless, nothing to provision, pay per query / per TB scanned.
			- No need to setup complex Extract/Transform/Load (ETL) processes.
			- Works directly with dats stored in S3.
	- What can Athena be used for?
		- Can be used to query log files stored in S3, e.g. ELB logs, S3 access logs etc.
		- Generate business reports on data stored in S3.
		- Analyse AWS cost and usage reports.
		- Run queries on click-stream data.
	- What is PII (Personally Identifiable Information)?
		- Personal data used to establish an individual's identity.
		- This data could be exploited by criminals, used in identity theft and financial fraud.
		- Home address, email, SSN.
		- Passport number, driver's license number.
		- DOB, phone number, bank account, credit card number.
	- What is Macie?
		- Macie is a security service which uses Machine Learning and NLP to discover, classify and protect sensitive data stored in S3.
			- Uses AI to recongnise if your S3 Objects contain sensitive data such as PII.
			- Dashboard, reporting and alerts.
			- Works directly with data stored in S3.
			- Can be analyze CloudTrail logs for suspicious API activities.
			- Great for PCI-DSS and preventing ID theft.
		
		
		
		  
		
	
	
	
	