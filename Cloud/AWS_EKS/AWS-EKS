==================================================================
		AWS EKS (Elasti Service for Kubernetes)
==================================================================
	
	===============================
	- Kubernetes on AWS before EKS
		
		- Kubernetes is taking IT by strom, with termendous adoption.
		- IT perfessional need to be able to create and operate K8s cluster.
		- Treditionally that meant deploy kubernetes yourself:
			- Deploy Master Nodes
			- Deploy Etcd
			- Setup CA for TCL encryption
			- Setup monitoring / auto scaling / self healing
			- Setup security such as authentication and authorization
			- Finally setup the worker nodes
		- After all this you'r finally done. (Just for setup)
	
	==========================
	- Kubernetes with AWS EKS
		
		- Its handles all hard kubernetes setup for you.
			- Master nodes in HA (High Availability)
			- Etcd esembled in HA
			- API server
			- KubeDNS
			- Scheduler
			- Controller Manager
			- Cloud Controller
		- And you just need to deploy the Worker Nodes and Your application.
		- Finally authentication will be handled through IAM !
	====================================	
	- EKS Setup Process (under the hood)
		
		- EKS will setup and manage out Kubernetes masters.
		
						>>>>>>>>>>>>>>>>>>> Internal AWS Creation Process >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
		Create EKS	=> 	K8s Master	=> 	Etcd 	=> 	IAM Plugin	=> 	CA setup	=> 	Auto Scaling	=>	Load Balancer 
		Cluster			in HA			in HA		Setup			(for TLS)							(NLB & ELB)
		
	============================	
	- Deep Integration with AWS
		
		- API calls can be audited in CloudTrail
		- Authentication is through IAM while authorization through RBAC
		- CloudFormation templates to manage your cluster
		- You can customize the AMI for your nodes.
		- Load Balancers, EBS Volumes, EFS, etc...
		- Container registries on ECR,
		- Network is handled with a per-pod IP address with attached ENI
		- CLI integration
		
		- But its still the Kubernetes Opensource Project!
	
	=======================
	- Amazon EKS use cases
		
		- You can create as many clusters you want as per your need.
		- Microservices in conatainers
		- Platform as a Service / Website
		- Migrate on-permise cluster to cloud Kubernetes cluster
		- Machine Learning cluster (Support for GPU instances)
		- And rest is you imagination 
		
	======================================
	- What We will Learn from This Course 
		
		- Deploy your EKS cluster using CloudFormation
		- Scale your Kubernetes cluster
		- Setup KubeCtl properly to access your cluster
		- Learn how EKS works under the hood and its integrations with AWS
		- Setup administration using the Kubernetes Dashboard
		- Deploy a stateless application on EKS and expose it with a public ELB
		- Deploy a stateful application on EKS and bind it with EBS volumes
		- Deploy a stateful application (such as wordpress) with EFS network drives
		- Manage your Kubernetes cluster using the AWS CLI and EksCtl CLI
		
	================================
	- Amazon EKS Architecture in HA		
	
									KubeCtl
										|
										|
						mycluster.eks.amanzonaws.com
						/				|			\	
					   /				|			 \
			AZ-A 					AZ-B					AZ-C
		================		================		================
			Master Node				Master Node				Master Node
			Etcd					Etcd					Etcd
			K8s Worker Nodes		K8s Worker Nodes		K8s Worker Nodes
		
		- Master node and Etcd is managed by EKS where as Worker Nodes are managed by user itself
		
	========================
	- EKS Pricing - Warning
		
		- Each EKS cluster cost $0.20 per hour
		- That's $144 per month
		- There is no free tier for EKS
		- On top of it, you will pay for worker nodes EC2 instances, EBS volumes, Load Balancers etc.
		
	========================
	- IAM User for EksCtl
		
		- IAM user need to be create with suficient permission, which can manage entire EKS cluster.
		- There are verious roles and policies need to be granted to this user. AdminstartorAccess, EKS, CloudFormation etc.
	
	========================
	- AWS EKS Cluster Setup
		
		- Prerequisites to grant access to IAM User
			-- Create IAM Role : K8s assumes this role to create AWS resources.
			-- Create SSH Key : To be able to SSH to you EC2 instances.
			-- Create Access Key+Secret : Enable authentication for API access.
			
		- Setup CommandLine CLI tools to your machine to interact with AWS, EKS and K8s Cluster. Install all below given tools.
			-- aws ctl : Required as dependency of eksctl to grab authentication token (Version 1.16.156 or greater). Prerequisites: Python & Python pip
			-- eksctl : setup and interact with EKS to manage EKS cluster and perform operatoins on them.
			-- kubectl : interaction with K8s API server.
		
		- Create EKS cluster via eksctl (https://eksctl.io)
			-- eksctl 
				--- eksctl is created by Weaveworks, then promoted to official AWS EKS cli (announcement summer 2019)
				--- creation & management of EKS cluster.
				--- create ymal file to provide a template to create EKS cluster using eksctl 
				--- take help of eksctl documentations (https://eksctl.io) for how to setup EKS cluster via eksctl.
				
			-- initial cluster inforamation
				--- region: us-east-1
				--- one nodegroup
				--- 3 worker nodes, type t2.small
				--- ssh access
	
	==================================
	- AWS EKS Operations using eksctl
		
		- NodeGroups & Spot Instances
			-- Amazon EKS managed nodegroups is a feature that automates the provisioning and lifecycle management of nodes (EC2 instances) 
				for Amazon EKS Kubernetes clusters. Customers can provision optimized groups of nodes for their clusters and EKS will keep 
				their nodes up to date with the latest Kubernetes and host OS versions. 
				
			-- Get eks cluster inforamation
				$ eksctl get cluster
			
			-- Get NodeGroup inforamation
				$ eksctl get nodegroup --cluster <cluster-name>
				
			-- Scaling a NodeGroup; to scale out you can also reduce number of node in given command
				$ eksctl scale nodegroup  --cluster=<cluster-name>  --nodes=5 --name=<nodegroup-name>
			
			-- Adding a NodeGroup: to update new nodegroup in cluster ymal file, add new nodegroup configuration with new name e.g. 'ng-2'
				$ eksctl create nodegroup -- config-file=eks-course.ymal --include='ng-2'
			
			-- Deleting a NodeGroup
				$ eksctl delete nodegroup --config-file=eks-course.ymal -include=ng-2 --approve
				
	===================================================
	- AWS EKS Cluster AutoScaler Theory: How its works
		
		- Responsible for dynamically scale the nodes within a nodegroup, in & out
		- Run as K8s deployment. (https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler)
		- Decides based on CPU & RAM availablity / Requestes.
		- Multiple-AZ vs Single-AZ scaling
			-- nodegroup with single-AZ --> for stateful workloads
			-- nodegroup with multiple-AZ --> for stateless workloads
		- Mixture of on-demand & spot-instances possible
				
	======================================
	- Cluster AutoScaler: Hands On
	
		- Create dedicated nodegroups with autoscaling enabled
			-- 2 NodeGroups with single AZ (e.g. for stateful workloads)
			-- 1 NodeGroup access 3 AZs using spot instances (e.g. for stateless workloads)
			
		- Deploy the autoscaler
			-- Create K8s deployment
			-- Add annotation to the deployment to prevent from being evicted.
			-- Set matching image version and cluster name in deployment 
			
		- Create nginx image K8s deployment and scale it up/down
		
		- View autoscaler logs
	
	==================================================
	- CloudWatch Logging for EKS Cluster Service
		
		- ControlPlane logging to CloudWatch:
			-- AWS ControlPlane is fully managed service for EKS cluster. You don't have any access to host which serving this ControlPlane.
			-- enable/disable per log type.
			-- log types:
				- api
				- audit
				- authenticator
				- controllerManager
				- scheduler
			-- view logs
				- each log type creates its own CloudWatch log steam.
				- name prefix /aws/eks/cluster-name/
			-- CloudWatch logging adds additional cost. (Storage & Collection)
	
	
		- Added cloudwatch configuration in cluster-config yaml file
		- YMAL example:
			cloudwatch:
				clusterlogging:
					enableTypes: ["api", "audit", "authentication"]
									or
					enableTypes: ["*"] # If you want all types enabled
					
		- Apply updated cluster-config yaml to EKS cluster
			$ eksctl utils update-cluster-logging --config-file eks-course.yaml --approve
			
		- Disable all enabled cluster logging types.	
			$ eksctl utils update-cluster-logging --name=EKS-course-cluster --disable-types all --approve
			
	==================================================
	- CloudWatch Containers Insights for EKS
	
		- CloudWatch metrics: Container insights
			-- add IAM policy (CloudWatchAgentServerPolicy) for access to cloudwatch agent to nodegroup role(s)
			-- deploy cloudwatch agent. one agent per node to collect logges from each node.
			-- view metrics
			
		- CloudWatch metrics adds additional cost. (Storage & Collection)
	
			
		
		
		